{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to subject folders\n",
    "subject_dirs = glob.glob(r'C:\\Users\\quanz\\Documents\\UM\\Projects\\GLX_Project\\DNN\\betafiles\\mindy*')\n",
    "\n",
    "# Dictionaries to store left and right hemisphere beta data for each subject\n",
    "left_hem_voxel_beta_values = {}\n",
    "right_hem_voxel_beta_values = {}\n",
    "\n",
    "# Load each hemisphere file for each subject\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_id = os.path.basename(subject_dir)  # Extract 'mindyXXX' as subject ID\n",
    "    \n",
    "    # Load left hemisphere data\n",
    "    left_hem_path = os.path.join(subject_dir, 'LeftHemUnsm12conds.mat')\n",
    "    left_hem_data = scipy.io.loadmat(left_hem_path)\n",
    "    \n",
    "    # Stack columns from cond1 and cond2 to form a (19076, 12) matrix\n",
    "    left_hem_beta = np.hstack([left_hem_data['cond1'], left_hem_data['cond2']])\n",
    "    left_hem_voxel_beta_values[subject_id] = left_hem_beta  # Should now be (19076, 12)\n",
    "\n",
    "    # Load right hemisphere data\n",
    "    right_hem_path = os.path.join(subject_dir, 'RightHemUnsm12conds.mat')\n",
    "    right_hem_data = scipy.io.loadmat(right_hem_path)\n",
    "    \n",
    "    # Stack columns from cond1 and cond2 to form a (19076, 12) matrix\n",
    "    right_hem_beta = np.hstack([right_hem_data['cond1'], right_hem_data['cond2']])\n",
    "    right_hem_voxel_beta_values[subject_id] = right_hem_beta  # Should now be (19076, 12)\n",
    "\n",
    "# Optional: Check shapes for one subject to confirm successful loading\n",
    "example_subject = list(left_hem_voxel_beta_values.keys())[0]\n",
    "print(\"Example Subject Left Hemisphere Shape:\", left_hem_voxel_beta_values[example_subject].shape)\n",
    "print(\"Example Subject Right Hemisphere Shape:\", right_hem_voxel_beta_values[example_subject].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare unit matrices for ridge regression\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define layer names as per your DNN structure\n",
    "layer_names = [ \n",
    "    'conv1', 'rnorm1', 'pool1', 'conv2', 'rnorm2', 'pool2',\n",
    "    'conv3', 'conv4_W', 'conv5_W', 'pool5_W', 'conv4_G', 'conv5_G', 'pool5_G'\n",
    "]\n",
    "\n",
    "# Path to .npy files for activations\n",
    "activation_path = r'C:\\Users\\quanz\\Documents\\UM\\Projects\\GLX_Project\\DNN\\MiND_Stimili'\n",
    "\n",
    "# Dictionary to store each layer's activation data\n",
    "activation_matrices = {}\n",
    "\n",
    "# Load each layer's .npy file and store it in activation_matrices\n",
    "for layer_name in layer_names:\n",
    "    # Adjust file name to match your format\n",
    "    file_path = os.path.join(activation_path, f'reduced_reduced_activation_matrix_{layer_name}.npy')\n",
    "    layer_data = np.load(file_path)\n",
    "    \n",
    "    # Ensure the data shape is (100, 12)\n",
    "    if layer_data.shape == (100, 120):\n",
    "        # Average every 10 columns to reduce to (100, 12)\n",
    "        layer_data = layer_data.reshape(100, 12, 10).mean(axis=2)\n",
    "    elif layer_data.shape != (100, 12):\n",
    "        raise ValueError(f\"Unexpected shape for {layer_name}: {layer_data.shape}\")\n",
    "    \n",
    "    # Store the processed data in the dictionary\n",
    "    activation_matrices[layer_name] = layer_data\n",
    "\n",
    "# Optional: Check the shapes to confirm all layers are correctly loaded\n",
    "for layer_name, data in activation_matrices.items():\n",
    "    print(f\"{layer_name}: shape {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is for ridge regression for all of the subjects:\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Select a single subject ID (e.g., the first subject in your data)\n",
    "single_subject_id = list(left_hem_voxel_beta_values.keys())[0]\n",
    "\n",
    "# Assuming activation_matrices is a dictionary with each DNN layer's data (shape: (100, 12))\n",
    "# left_hem_voxel_beta_values and right_hem_voxel_beta_values contain the beta data for each hemisphere and subject\n",
    "\n",
    "# Dictionary to store fit scores for each hemisphere and layer\n",
    "fit_scores = {\n",
    "    \"left\": {layer_name: [] for layer_name in activation_matrices.keys()},\n",
    "    \"right\": {layer_name: [] for layer_name in activation_matrices.keys()},\n",
    "}\n",
    "\n",
    "# Run ridge regression for left and right hemispheres separately\n",
    "for layer_name, X in activation_matrices.items():  # X has shape (100, 12)\n",
    "    X = X.T  # Transpose to shape (12, 100), aligning with 12 conditions\n",
    "    \n",
    "    # Process left hemisphere data\n",
    "    for subject_id, left_hem_beta in left_hem_voxel_beta_values.items():\n",
    "        subject_fit_scores_left = []\n",
    "        for voxel_idx in range(left_hem_beta.shape[0]):\n",
    "            y = left_hem_beta[voxel_idx, :]  # Voxel responses across 12 conditions\n",
    "            ridge = Ridge(alpha=1.0)  # You can adjust alpha as needed\n",
    "            ridge.fit(X, y)\n",
    "            y_pred = ridge.predict(X)\n",
    "            score = r2_score(y, y_pred)  # R² score as the fit metric\n",
    "            subject_fit_scores_left.append(score)\n",
    "        fit_scores[\"left\"][layer_name].append(subject_fit_scores_left)\n",
    "\n",
    "    # Process right hemisphere data\n",
    "    for subject_id, right_hem_beta in right_hem_voxel_beta_values.items():\n",
    "        subject_fit_scores_right = []\n",
    "        for voxel_idx in range(right_hem_beta.shape[0]):\n",
    "            y = right_hem_beta[voxel_idx, :]  # Voxel responses across 12 conditions\n",
    "            ridge = Ridge(alpha=1.0)\n",
    "            ridge.fit(X, y)\n",
    "            y_pred = ridge.predict(X)\n",
    "            score = r2_score(y, y_pred)\n",
    "            subject_fit_scores_right.append(score)\n",
    "        fit_scores[\"right\"][layer_name].append(subject_fit_scores_right)\n",
    "\n",
    "# Convert scores to arrays for easier handling (optional)\n",
    "for hemi in fit_scores:\n",
    "    for layer_name in fit_scores[hemi]:\n",
    "        fit_scores[hemi][layer_name] = np.array(fit_scores[hemi][layer_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Select a single subject ID (e.g., the first subject in your data)\n",
    "single_subject_id = list(left_hem_voxel_beta_values.keys())[0]\n",
    "\n",
    "# Dictionary to store fit scores for each hemisphere and layer for the single subject\n",
    "fit_scores_single_subject = {\n",
    "    \"left\": {layer_name: [] for layer_name in activation_matrices.keys()},\n",
    "    \"right\": {layer_name: [] for layer_name in activation_matrices.keys()},\n",
    "}\n",
    "\n",
    "# Run ridge regression for each layer and each hemisphere for the single subject\n",
    "for layer_name, X in activation_matrices.items():  # X has shape (100, 12)\n",
    "    X = X.T  # Transpose to shape (12, 100) for compatibility with voxel data\n",
    "\n",
    "    # Standardize the activations in X (if not already standardized)\n",
    "    scaler_X = StandardScaler()\n",
    "    X = scaler_X.fit_transform(X)  # Now X is standardized\n",
    "\n",
    "    # Process left hemisphere data for the single subject, voxel by voxel\n",
    "    left_hem_beta = left_hem_voxel_beta_values[single_subject_id]  # Shape: (19076, 12)\n",
    "    for voxel_idx in range(left_hem_beta.shape[0]):\n",
    "        y = left_hem_beta[voxel_idx, :]  # Voxel responses across 12 conditions\n",
    "\n",
    "        # Standardize y\n",
    "        scaler_y = StandardScaler()\n",
    "        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Ridge regression with scaled y\n",
    "        ridge = Ridge(alpha=10.0)\n",
    "        ridge.fit(X, y_scaled)\n",
    "\n",
    "        # Predict and inverse-transform to original scale\n",
    "        y_pred_scaled = ridge.predict(X)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Calculate R² score on the original scale\n",
    "        score = r2_score(y, y_pred)\n",
    "        fit_scores_single_subject[\"left\"][layer_name].append(score)\n",
    "\n",
    "    # Process right hemisphere data for the single subject, voxel by voxel\n",
    "    right_hem_beta = right_hem_voxel_beta_values[single_subject_id]  # Shape: (19076, 12)\n",
    "    for voxel_idx in range(right_hem_beta.shape[0]):\n",
    "        y = right_hem_beta[voxel_idx, :]  # Voxel responses across 12 conditions\n",
    "\n",
    "        # Standardize y\n",
    "        scaler_y = StandardScaler()\n",
    "        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Ridge regression with scaled y\n",
    "        ridge = Ridge(alpha=10.0)\n",
    "        ridge.fit(X, y_scaled)\n",
    "\n",
    "        # Predict and inverse-transform to original scale\n",
    "        y_pred_scaled = ridge.predict(X)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Calculate R² score on the original scale\n",
    "        score = r2_score(y, y_pred)\n",
    "        fit_scores_single_subject[\"right\"][layer_name].append(score)\n",
    "\n",
    "# Optional: Convert scores to arrays for easier handling\n",
    "for hemi in fit_scores_single_subject:\n",
    "    for layer_name in fit_scores_single_subject[hemi]:\n",
    "        fit_scores_single_subject[hemi][layer_name] = np.array(fit_scores_single_subject[hemi][layer_name])\n",
    "\n",
    "# Check scores for the single subject\n",
    "print(\"Fit scores for the single subject:\", fit_scores_single_subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare a list to store each score entry with details\n",
    "data_to_save = []\n",
    "\n",
    "# Loop through each hemisphere, layer, and voxel to structure the data\n",
    "for hemi, layers in fit_scores_single_subject.items():\n",
    "    for layer_name, scores in layers.items():\n",
    "        for voxel_idx, score in enumerate(scores):\n",
    "            data_to_save.append({\n",
    "                \"Hemisphere\": hemi,\n",
    "                \"Layer\": layer_name,\n",
    "                \"Voxel_Index\": voxel_idx,\n",
    "                \"R2_Score\": score\n",
    "            })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df_scores = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save to CSV\n",
    "df_scores.to_csv(\"fit_scores_single_subject.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes of R² score arrays within fit_scores_single_subject\n",
    "for hemi, layers in fit_scores_single_subject.items():\n",
    "    print(f\"Hemisphere: {hemi}\")\n",
    "    for layer_name, scores in layers.items():\n",
    "        print(f\"  Layer: {layer_name}, Number of voxels: {len(scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
